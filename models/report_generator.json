{"id":"cde9e5f7-aaf2-48b8-926c-49525cefbe0b","data":{"nodes":[{"data":{"description":"Create a prompt template with dynamic variables.","display_name":"Prompt","id":"Prompt-KYPlF","node":{"template":{"Document":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"Document","display_name":"Document","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"},"template":{"advanced":false,"display_name":"Template","dynamic":false,"info":"","list":false,"load_from_db":false,"name":"template","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"type":"prompt","value":"Write a report in {Language} based on the following Database, Document, Format:\n---\nDatabase:\n{Database}\n---\n\n---\nDocument:\n{Document}\n---\n\nFormat:\n{Format}\n\nAnswer:\n"},"Database":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"Database","display_name":"Database","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"Language":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"Language","display_name":"Language","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"Format":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"Format","display_name":"Format","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["Language","Database","Document","Format"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true,"required_inputs":null}],"field_order":["template"],"beta":false,"error":null,"edited":false,"metadata":{},"lf_version":"1.0.19.post1"},"type":"Prompt"},"dragging":false,"height":646,"id":"Prompt-KYPlF","position":{"x":628.6730582816892,"y":-81.90552267198625},"positionAbsolute":{"x":628.6730582816892,"y":-81.90552267198625},"selected":false,"type":"genericNode","width":384},{"data":{"description":"Display a chat message in the Playground.","display_name":"Chat Output","id":"ChatOutput-q9brN","node":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Display a chat message in the Playground.","display_name":"Chat Output","documentation":"","edited":false,"field_order":["input_value","store_message","sender","sender_name","session_id","data_template"],"frozen":false,"icon":"ChatOutput","metadata":{},"output_types":[],"outputs":[{"cache":true,"display_name":"Message","method":"message_response","name":"message","selected":"Message","types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"},"data_template":{"advanced":true,"display_name":"Data Template","dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","input_types":["Message"],"list":false,"load_from_db":false,"name":"data_template","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{text}"},"input_value":{"advanced":false,"display_name":"Text","dynamic":false,"info":"Message to be passed as output.","input_types":["Message"],"list":false,"load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"sender":{"advanced":true,"display_name":"Sender Type","dynamic":false,"info":"Type of sender.","name":"sender","options":["Machine","User"],"placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"str","value":"Machine"},"sender_name":{"advanced":true,"display_name":"Sender Name","dynamic":false,"info":"Name of the sender.","input_types":["Message"],"list":false,"load_from_db":false,"name":"sender_name","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"AI"},"session_id":{"advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","input_types":["Message"],"list":false,"load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"should_store_message":{"_input_type":"BoolInput","advanced":true,"display_name":"Store Messages","dynamic":false,"info":"Store the message in the history.","list":false,"name":"should_store_message","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"bool","value":true}},"lf_version":"1.0.19.post1"},"type":"ChatOutput"},"dragging":false,"height":288,"id":"ChatOutput-q9brN","position":{"x":1934.444253545719,"y":92.01770946409115},"positionAbsolute":{"x":1934.444253545719,"y":92.01770946409115},"selected":true,"type":"genericNode","width":384},{"data":{"description":"Convert Data into plain text following a specified template.","display_name":"Parse Data","id":"ParseData-f9hBM","node":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert Data into plain text following a specified template.","display_name":"Parse Data","documentation":"","edited":false,"field_order":["data","template","sep"],"frozen":false,"icon":"braces","metadata":{},"output_types":[],"outputs":[{"cache":true,"display_name":"Text","method":"parse_data","name":"text","selected":"Message","types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n"},"data":{"advanced":false,"display_name":"Data","dynamic":false,"info":"The data to convert to text.","input_types":["Data"],"list":false,"name":"data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"sep":{"advanced":true,"display_name":"Separator","dynamic":false,"info":"","list":false,"load_from_db":false,"name":"sep","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"str","value":"\n"},"template":{"advanced":false,"display_name":"Template","dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","input_types":["Message"],"list":false,"load_from_db":false,"multiline":true,"name":"template","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{text}"}},"lf_version":"1.0.19.post1"},"type":"ParseData"},"dragging":false,"height":352,"id":"ParseData-f9hBM","position":{"x":87.26129917199853,"y":-181.46350622708565},"positionAbsolute":{"x":87.26129917199853,"y":-181.46350622708565},"selected":false,"type":"genericNode","width":384},{"data":{"description":"A generic file loader.","display_name":"File","id":"File-51d1E","node":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A generic file loader.","display_name":"File","documentation":"","edited":false,"field_order":["path","silent_errors"],"frozen":false,"icon":"file-text","metadata":{},"output_types":[],"outputs":[{"cache":true,"display_name":"Data","method":"load_file","name":"data","selected":"Data","types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, FileInput, Output\nfrom langflow.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            msg = \"Please, upload a file to use this component.\"\n            raise ValueError(msg)\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            msg = \"doc files are not supported. Please save as .docx\"\n            raise ValueError(msg)\n        if extension not in TEXT_FILE_TYPES:\n            msg = f\"Unsupported file type: {extension}\"\n            raise ValueError(msg)\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data or \"No data\"\n        return data or Data()\n"},"path":{"advanced":false,"display_name":"Path","dynamic":false,"fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx"],"file_path":"cde9e5f7-aaf2-48b8-926c-49525cefbe0b\\2024-11-11_11-09-09_real_estate.txt","info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","list":false,"name":"path","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"file","value":""},"silent_errors":{"advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"bool","value":false}},"lf_version":"1.0.19.post1"},"type":"File"},"dragging":false,"height":288,"id":"File-51d1E","position":{"x":-503.5482694172084,"y":-189.37436239651962},"positionAbsolute":{"x":-503.5482694172084,"y":-189.37436239651962},"selected":false,"type":"genericNode","width":384},{"id":"TextInput-G353c","type":"genericNode","position":{"x":86.2839260183573,"y":259.6340456630391},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"Please extract and provide the following details for each component of the property:\nDate: [Date of Assessment]\nArea Assessed: [Area Assessed]\nLocation: [Detail Location]\nAssessor: [Your Name]\nDescription: list each component of the property and its description (e.g., living space, bedrooms, backyard, garage, etc.).\nCondition Assessment: For each component listed in the Description, provide the following information:\n- Positive: List any positive aspects or conditions of the component.\n- Negative: List any negative aspects or conditions of the component.\n- Recommendations: Provide any recommendations for improvement, maintenance, or changes needed.\nOverall Assessment: Provide a general evaluation of the property's condition based on the above information. Summarize if the property is in good condition, requires improvements, or needs any specific attention.\nNext Steps: List the next steps required for maintenance, repairs, or other actions to be taken for the property, based on the assessment.\n\nEnsure that the output is clearly organized and detailed, with each section well-separated and providing sufficient information for decision-making without formatting as a table","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Template","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false,"metadata":{},"lf_version":"1.0.19.post1"},"id":"TextInput-G353c"},"selected":false,"width":384,"height":288,"positionAbsolute":{"x":86.2839260183573,"y":259.6340456630391},"dragging":false},{"id":"GoogleGenerativeAIModel-Y5YQH","type":"genericNode","position":{"x":1297.8597575962851,"y":-93.97527232003134},"data":{"type":"GoogleGenerativeAIModel","node":{"template":{"_type":"Component","output_parser":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"output_parser","value":"","display_name":"Output Parser","advanced":true,"input_types":["OutputParser"],"dynamic":false,"info":"The parser to use to parse the output of the model","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=[\"gemini-1.5-pro\", \"gemini-1.5-flash\", \"gemini-1.0-pro\", \"gemini-1.0-pro-vision\"],\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key),\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"google_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"google_api_key","value":"AIzaSyDF2pxp22kJ0QPW8MD40sZREc86XHfkwD4","display_name":"Google API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The Google API Key to use for the Google Generative AI.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"max_output_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_output_tokens","value":"","display_name":"Max Output Tokens","advanced":false,"dynamic":false,"info":"The maximum number of tokens to generate.","title_case":false,"type":"int","_input_type":"IntInput"},"model":{"trace_as_metadata":true,"options":["gemini-1.5-pro","gemini-1.5-flash","gemini-1.0-pro","gemini-1.0-pro-vision"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model","value":"gemini-1.5-flash","display_name":"Model","advanced":false,"dynamic":false,"info":"The name of the model to use.","title_case":false,"type":"str","_input_type":"DropdownInput"},"n":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"n","value":"","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"},"top_k":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"top_k","value":"","display_name":"Top K","advanced":true,"dynamic":false,"info":"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.","title_case":false,"type":"int","_input_type":"IntInput"},"top_p":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"top_p","value":"","display_name":"Top P","advanced":true,"dynamic":false,"info":"The maximum cumulative probability of tokens to consider when sampling.","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generate text using Google Generative AI.","icon":"GoogleGenerativeAI","base_classes":["LanguageModel","Message"],"display_name":"Google Generative AI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"required_inputs":["input_value","stream","system_message"]},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true,"required_inputs":["google_api_key","max_output_tokens","model","n","temperature","top_k","top_p"]}],"field_order":["input_value","system_message","stream","max_output_tokens","model","google_api_key","top_p","temperature","n","top_k","output_parser"],"beta":false,"edited":false,"metadata":{},"lf_version":"1.0.19.post1"},"id":"GoogleGenerativeAIModel-Y5YQH"},"selected":false,"width":384,"height":670,"positionAbsolute":{"x":1297.8597575962851,"y":-93.97527232003134},"dragging":false},{"id":"File-vxvhj","type":"genericNode","position":{"x":-492.55426364388484,"y":-739.4797132867922},"data":{"description":"A generic file loader.","display_name":"File","id":"File-vxvhj","node":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A generic file loader.","display_name":"File","documentation":"","edited":false,"field_order":["path","silent_errors"],"frozen":false,"icon":"file-text","metadata":{},"output_types":[],"outputs":[{"cache":true,"display_name":"Data","method":"load_file","name":"data","selected":"Data","types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, FileInput, Output\nfrom langflow.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            msg = \"Please, upload a file to use this component.\"\n            raise ValueError(msg)\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            msg = \"doc files are not supported. Please save as .docx\"\n            raise ValueError(msg)\n        if extension not in TEXT_FILE_TYPES:\n            msg = f\"Unsupported file type: {extension}\"\n            raise ValueError(msg)\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data or \"No data\"\n        return data or Data()\n"},"path":{"advanced":false,"display_name":"Path","dynamic":false,"fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx"],"file_path":"cde9e5f7-aaf2-48b8-926c-49525cefbe0b\\2024-11-11_11-37-46_database.txt","info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","list":false,"name":"path","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"file","value":""},"silent_errors":{"advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"bool","value":false}},"lf_version":"1.0.19.post1"},"type":"File"},"selected":false,"width":384,"height":288,"positionAbsolute":{"x":-492.55426364388484,"y":-739.4797132867922},"dragging":false},{"id":"ParseData-gipf5","type":"genericNode","position":{"x":79.89661323181019,"y":-727.92701110363},"data":{"description":"Convert Data into plain text following a specified template.","display_name":"Parse Data","id":"ParseData-gipf5","node":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert Data into plain text following a specified template.","display_name":"Parse Data","documentation":"","edited":false,"field_order":["data","template","sep"],"frozen":false,"icon":"braces","metadata":{},"output_types":[],"outputs":[{"cache":true,"display_name":"Text","method":"parse_data","name":"text","selected":"Message","types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n"},"data":{"advanced":false,"display_name":"Data","dynamic":false,"info":"The data to convert to text.","input_types":["Data"],"list":false,"name":"data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"sep":{"advanced":true,"display_name":"Separator","dynamic":false,"info":"","list":false,"load_from_db":false,"name":"sep","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"str","value":"\n"},"template":{"advanced":false,"display_name":"Template","dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","input_types":["Message"],"list":false,"load_from_db":false,"multiline":true,"name":"template","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{text}"}},"lf_version":"1.0.19.post1"},"type":"ParseData"},"selected":false,"width":384,"height":352,"positionAbsolute":{"x":79.89661323181019,"y":-727.92701110363},"dragging":false},{"id":"TextInput-kX0LZ","type":"genericNode","position":{"x":31.419533690620028,"y":690.4748611409148},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"vietnamese","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false,"metadata":{},"lf_version":"1.0.19.post1"},"id":"TextInput-kX0LZ"},"selected":false,"width":384,"height":288,"positionAbsolute":{"x":31.419533690620028,"y":690.4748611409148},"dragging":false}],"edges":[{"className":"","data":{"sourceHandle":{"dataType":"File","id":"File-51d1E","name":"data","output_types":["Data"]},"targetHandle":{"fieldName":"data","id":"ParseData-f9hBM","inputTypes":["Data"],"type":"other"}},"id":"reactflow__edge-File-51d1E{œdataTypeœ:œFileœ,œidœ:œFile-51d1Eœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-f9hBM{œfieldNameœ:œdataœ,œidœ:œParseData-f9hBMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","source":"File-51d1E","sourceHandle":"{œdataTypeœ:œFileœ,œidœ:œFile-51d1Eœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-f9hBM","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-f9hBMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","animated":false},{"source":"Prompt-KYPlF","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-KYPlFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"GoogleGenerativeAIModel-Y5YQH","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-Y5YQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"GoogleGenerativeAIModel-Y5YQH","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-KYPlF","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-KYPlF{œdataTypeœ:œPromptœ,œidœ:œPrompt-KYPlFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-Y5YQH{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-Y5YQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"ParseData-f9hBM","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-f9hBMœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-KYPlF","targetHandle":"{œfieldNameœ:œDocumentœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Document","id":"Prompt-KYPlF","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-f9hBM","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-f9hBM{œdataTypeœ:œParseDataœ,œidœ:œParseData-f9hBMœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-KYPlF{œfieldNameœ:œDocumentœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"File-vxvhj","sourceHandle":"{œdataTypeœ:œFileœ,œidœ:œFile-vxvhjœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-gipf5","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-gipf5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-gipf5","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"File","id":"File-vxvhj","name":"data","output_types":["Data"]}},"id":"reactflow__edge-File-vxvhj{œdataTypeœ:œFileœ,œidœ:œFile-vxvhjœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-gipf5{œfieldNameœ:œdataœ,œidœ:œParseData-gipf5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","animated":false,"className":""},{"source":"ParseData-gipf5","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-gipf5œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-KYPlF","targetHandle":"{œfieldNameœ:œDatabaseœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Database","id":"Prompt-KYPlF","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-gipf5","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-gipf5{œdataTypeœ:œParseDataœ,œidœ:œParseData-gipf5œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-KYPlF{œfieldNameœ:œDatabaseœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"GoogleGenerativeAIModel-Y5YQH","sourceHandle":"{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-Y5YQHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"ChatOutput-q9brN","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-q9brNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-q9brN","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"GoogleGenerativeAIModel","id":"GoogleGenerativeAIModel-Y5YQH","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-GoogleGenerativeAIModel-Y5YQH{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-Y5YQHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-q9brN{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-q9brNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"TextInput-kX0LZ","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-kX0LZœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-KYPlF","targetHandle":"{œfieldNameœ:œLanguageœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Language","id":"Prompt-KYPlF","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-kX0LZ","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-kX0LZ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-kX0LZœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-KYPlF{œfieldNameœ:œLanguageœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"TextInput-G353c","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-G353cœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-KYPlF","targetHandle":"{œfieldNameœ:œFormatœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Format","id":"Prompt-KYPlF","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-G353c","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-G353c{œdataTypeœ:œTextInputœ,œidœ:œTextInput-G353cœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-KYPlF{œfieldNameœ:œFormatœ,œidœ:œPrompt-KYPlFœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","animated":false,"className":""}],"viewport":{"x":-192.03879956239683,"y":253.93193352524224,"zoom":0.4468325278386167}},"description":"This flow integrates PDF reading with a language model to answer document-specific questions. Ideal for small-scale texts, it facilitates direct queries with immediate insights.","name":"Report Generator","last_tested_version":"1.0.19.post1","endpoint_name":null,"is_component":false}